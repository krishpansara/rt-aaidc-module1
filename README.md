# ğŸ§  RAG-Based Question Answering Assistant using LLMs

## ğŸ¤– What is this?

A **Retrieval-Augmented Generation (RAG)** powered assistant built using **LangChain** and **vector databases (FAISS/Chroma)** that can answer user questions based on custom documents.  
This project was developed as part of **AAIDC Module 1 â€“ â€œFoundations of Agentic AI: Your First RAG Assistantâ€**.

**Think of it as:** Your PA that knows about YOUR documents and can answer questions about them.

---

## ğŸš€ Project Overview

This project demonstrates how **Large Language Models (LLMs)** can be enhanced using **retrieval-based augmentation** to provide accurate, context-specific answers.  
Instead of relying solely on the modelâ€™s internal knowledge, it retrieves relevant information from ingested documents, enabling domain-specific Q&A.

You can interact with this assistant through a **Command-Line Interface (CLI)**, and optionally via a **Streamlit UI** for an improved user experience.

---

## ğŸ§© Key Features

- ğŸ“„ **Custom Document Ingestion** â€“ Upload and index your own documents (PDFs, text, or markdown).  
- ğŸ” **Vector Store Retrieval** â€“ Uses FAISS or Chroma to store embeddings and retrieve relevant context.  
- ğŸ¤– **LLM-Powered Responses** â€“ Generates natural, context-aware answers using OpenAI, Groq, or Gemini APIs.  
- ğŸ§  **LangChain Integration** â€“ Handles the end-to-end prompt â†’ retrieval â†’ response pipeline.  
- ğŸ§¾ **Configurable Pipeline** â€“ Supports easy switching between vector databases and models.  
- ğŸ—‚ï¸ **Extensible Design** â€“ Can be enhanced with session memory, logging, or reasoning chains (ReAct, CoT).  

---

## ğŸ§± Tech Stack

| Component | Technology |
|------------|-------------|
| Framework | **LangChain** |
| Vector Store | **FAISS** or **Chroma** |
| Embeddings | **OpenAI**, **Groq**, or **Gemini** |
| LLM Backend | **OpenAI GPT**, **Gemini**, or other API models |
| Interface | **CLI** (with optional **Streamlit** UI) |
| Language | **Python 3.10+** |

---

## ğŸ“‚ Folder Structure

```
rt-aaidc-module1/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py           # Main RAG application
â”‚   â””â”€â”€ vectordb.py      # Vector database wrapper
â”œâ”€â”€ data/               # Contains documnets
â”‚   â”œâ”€â”€ *.txt          # Contains text files
â”œâ”€â”€ requirements.txt    # All dependencies included
â””â”€â”€ README.md          # This guide
```




## ğŸ“ Learning Outcomes

By completing this project, youâ€™ll learn to:
- Implement a **Retrieval-Augmented Generation (RAG)** pipeline  
- Use **vector databases** for semantic search  
- Work with **embeddings** and **LLMs**  
- Design **prompt templates** for context-driven answers  
- Build real-world **AI assistant applications**

---






## âš™ï¸ Installation & Setup

Follow the steps below to set up and run the project locally:

### 1ï¸âƒ£ Clone the repository
   ```bash
   git clone https://github.com/krishpansara/rt-aaidc-module1/
   cd rt-aaidc-module1
   ```

### 2ï¸âƒ£ Create and Activate a Virtual Environment

Itâ€™s recommended to create a virtual environment to isolate project dependencies.

#### ğŸªŸ For Windows:
```bash
python -m venv venv
venv\Scripts\activate
```

#### ğŸ§ For macOS / Linux:
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install the Required Dependencies

Once the virtual environment is activated, install all dependencies using:
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure your API key:

This project supports multiple LLM providers (OpenAI, Groq, Google).  
You need to set your API keys before running the app.

After creating the Virtual Environment your project containes `.env` file in the project root directory add your API keys in the file as shown below:

```bash
# .env file

# Example: use one or more providers depending on your setup
OPENAI_API_KEY=your_openai_api_key_here
GROQ_API_KEY=your_groq_api_key_here
GOOGLE_API_KEY=your_google_api_key_here
```

### 5ï¸âƒ£ Run the Application
```bash
  python app.py
```

---


## ğŸ‘¤ Author

**Krish Pansara**  
ğŸ’» Passionate about AI, ML, and building intelligent applications.  
ğŸ”— [GitHub Profile](https://github.com/krishpansara)

